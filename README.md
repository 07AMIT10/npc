# ğŸ® NPC Arena v2

A browser-based AI arena game where LLM-powered NPCs compete in team-based challenges. Watch AI agents explore, strategize, and solve puzzles in real-time!

![NPC Arena Screenshot](docs/screenshot.png)

## âœ¨ Features

- **4 AI NPCs** in 2 competing teams (Red vs Blue)
- **Real-time LLM decisions** using Groq/Gemini APIs
- **Team-based challenges** requiring coordination
- **Zone exploration** with locked gates and puzzles
- **Live commentary** generated by AI
- **WebSocket** real-time updates

## ğŸš€ Quick Start

```bash
# Clone the repo
git clone https://github.com/07AMIT10/npc.git
cd npc

# Set up API keys
export GROQ_API_KEY=your_groq_key      # Fast action decisions
export GEMINI_API_KEY=your_gemini_key  # Strategic brain

# Run the server
go run ./cmd/server/main.go

# Open http://localhost:8080
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser UI  â”‚ â†â†’  â”‚  Go Server  â”‚ â†â†’  â”‚  LLM APIs    â”‚
â”‚  (Canvas)    â”‚ WS  â”‚  (Fiber)    â”‚     â”‚ (Groq/Gemini)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
npc/
â”œâ”€â”€ cmd/server/main.go       # Entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/                 # LLM integration & orchestration
â”‚   â”œâ”€â”€ llm/                 # Provider adapters & load balancing
â”‚   â”œâ”€â”€ game/                # World, teams, zones
â”‚   â”œâ”€â”€ challenge/           # Puzzle system
â”‚   â””â”€â”€ observability/       # Tracing & audit logs
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html           # Game page
â”‚   â”œâ”€â”€ game.js              # Canvas rendering
â”‚   â””â”€â”€ style.css            # Dark theme UI
â””â”€â”€ config.yaml              # Configuration
```

---

# ğŸ“‹ Implementation Roadmap

## Current Focus Areas

1. **Cost Optimization** - Reduce LLM API costs
2. **Visual Polish** - Modern UI with animations
3. **Scalability** - Prepare for deployment

---

## ğŸ”´ Phase 1: Cost Optimization

### Problem
Currently: 4 NPCs Ã— 15 decisions/min = **60 API calls/minute**

### Solution: Multi-NPC Single Prompt

Instead of 4 separate API calls, combine all NPCs into ONE prompt:

```go
// Before: 4 calls
for _, npc := range npcs {
    decision := callLLM(npc.observation)
}

// After: 1 call
combinedPrompt := `
NPCs:
1. Explorer (red) at [100,100], sees gate at dist 350
2. Scout (red) at [200,150], sees Wanderer at dist 400
3. Wanderer (blue) at [800,600], sees gate at dist 250
4. Seeker (blue) at [750,550], idle

Respond with decisions for ALL NPCs as JSON array.
`
decisions := callLLM(combinedPrompt) // 1 call instead of 4!
```

**Expected savings: ~75%**

### Additional Optimizations

| Optimization | Savings |
|-------------|---------|
| Multi-NPC prompts | 75% fewer calls |
| Decision caching | 30% cache hits |
| Token compression | 73% smaller prompts |
| **Total** | **~85% reduction** |

---

## ğŸ¨ Phase 2: Visual Polish (React Migration)

### Current State
- Vanilla JS (1274 lines in single file)
- Basic canvas rendering
- No animations or effects

### Target Architecture

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ GameCanvas/          # Canvas + particle system
â”‚   â”œâ”€â”€ Sidebar/             # React components
â”‚   â”œâ”€â”€ Header/              # Animated scoreboard
â”‚   â””â”€â”€ Overlay/             # Tooltips, modals
â”œâ”€â”€ store/
â”‚   â””â”€â”€ gameStore.ts         # Zustand state
â””â”€â”€ hooks/
    â””â”€â”€ useWebSocket.ts      # WS connection
```

### Planned Visual Features

| Feature | Description |
|---------|-------------|
| **Particle System** | Movement trails, gate unlock effects |
| **Animated Scores** | Count-up animation with glow |
| **Tooltips** | Hover over NPCs/gates for info |
| **Minimap** | Overview in corner |
| **Smooth Transitions** | Framer Motion animations |

### Particle Effects

```typescript
class ParticleSystem {
  // NPC movement - subtle dust trail
  emitMovementTrail(x, y, color) {...}
  
  // Gate unlock - celebration burst
  emitGateUnlock(x, y) {...}
  
  // Challenge - thinking sparkles
  emitThinkingSparkles(npc) {...}
}
```

---

## ğŸš€ Phase 3: Deployment

### Hosting Comparison

| Platform | Cost | Cold Start | Best For |
|----------|------|------------|----------|
| **Render** | Free | 30s after 15min | Getting started |
| **Fly.io** | ~$0-5/mo | <1s | Production |
| **Railway** | Free tier | Similar to Render | Quick deploys |

### Quick Deploy to Render

[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy)

1. **Fork this repo** on GitHub
2. **Create new Web Service** on [Render](https://render.com)
3. **Connect your GitHub repo**
4. **Set environment variables:**
   - `GROQ_API_KEY` - Your Groq API key
   - `GEMINI_API_KEY` - Your Gemini API key
5. **Deploy!**

### Keep-Alive with UptimeRobot

1. Sign up at [UptimeRobot](https://uptimerobot.com/) (free)
2. Create HTTP(s) monitor
3. URL: `https://your-app.onrender.com/health`
4. Interval: 14 minutes
5. Server stays awake during monitored hours!

### Local Docker Build

```bash
docker build -t npc-arena .
docker run -p 8080:8080 \
  -e GROQ_API_KEY=your_key \
  -e GEMINI_API_KEY=your_key \
  npc-arena
```

---

## ğŸ”§ Go-Specific Improvements

### 1. Context Cancellation
Enable cancelling in-flight LLM calls when users reset:
```go
ctx, cancel := context.WithCancel(context.Background())
// User clicks Reset â†’ cancel() â†’ saves API tokens
```

### 2. Connection Pooling
```go
transport := &http.Transport{
    MaxIdleConns:        100,
    MaxIdleConnsPerHost: 10,
}
```

### 3. Rate Limiting with stdlib
```go
import "golang.org/x/time/rate"
limiter := rate.NewLimiter(rate.Limit(5), 5)
limiter.Wait(ctx) // Context-aware!
```

---

## ğŸ”‘ API Configuration

### Environment Variables

```bash
# Fast SLM (pick one)
GROQ_API_KEY=xxx            # Recommended
SAMBANOVA_API_KEY=xxx
HF_API_KEY=xxx

# Brain LLM
GEMINI_API_KEY=xxx          # Recommended

# Optional: Per-NPC overrides
NPC_EXPLORER_PROVIDER=groq
NPC_EXPLORER_MODEL=llama-3.1-70b
```

### Config File (config.yaml)

```yaml
game:
  tick_rate: 60
  decision_rate: 2
  
model_roles:
  movement:
    provider: groq
    model: llama-3.1-8b-instant
  challenge:
    provider: gemini
    model: gemini-2.0-flash
```

---

## ğŸ¯ Controls

| Button | Action |
|--------|--------|
| â–¶ Start | Begin simulation |
| â¸ Pause | Freeze NPCs |
| ğŸ”„ Reset | Restart world |

---

## ğŸ“Š Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /` | Game UI |
| `GET /health` | Server status |
| `GET /stats` | LLM statistics |
| `GET /test` | Test all providers |
| `WS /ws` | Real-time game updates |

---

## ğŸ› ï¸ Development

```bash
# Run with hot reload
go run ./cmd/server/main.go

# Run tests
go test ./...

# Build binary
go build -o npc-server ./cmd/server
```

---

## ğŸ“ License

MIT

---

## ğŸ™ Acknowledgments

- [Groq](https://groq.com/) - Ultra-fast LLM inference
- [Google Gemini](https://ai.google.dev/) - Strategic AI
- [Fiber](https://gofiber.io/) - Go web framework
